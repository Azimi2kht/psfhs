{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b7b7a5",
   "metadata": {
    "executionInfo": {
     "elapsed": 7186,
     "status": "ok",
     "timestamp": 1702553778384,
     "user": {
      "displayName": "Azimi2kht",
      "userId": "01921100736619125997"
     },
     "user_tz": -210
    },
    "id": "857a5f70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 06:58:42.140850: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-10 06:58:42.361032: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-10 06:58:43.343068: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.7/lib64:/usr/local/cuda-11.7/lib64{LD_LIBRARY_PATH:+:}:/home/azimi2kht/miniconda3/envs/psfh/lib/:/home/azimi2kht/miniconda3/envs/psfh/lib/\n",
      "2024-07-10 06:58:43.343256: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.7/lib64:/usr/local/cuda-11.7/lib64{LD_LIBRARY_PATH:+:}:/home/azimi2kht/miniconda3/envs/psfh/lib/:/home/azimi2kht/miniconda3/envs/psfh/lib/\n",
      "2024-07-10 06:58:43.343270: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import tensorflow as tf\n",
    "import albumentations as albu\n",
    "import numpy as np\n",
    "import gc\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import CSVLogger\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, accuracy_score, f1_score\n",
    "from ModelArchitecture.DiceLoss import dice_metric_loss\n",
    "from ModelArchitecture import DUCK_Net\n",
    "from ImageLoader import ImageLoader2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1263919",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1702553779333,
     "user": {
      "displayName": "Azimi2kht",
      "userId": "01921100736619125997"
     },
     "user_tz": -210
    },
    "id": "7852dbbf-f3a4-4db6-8c5e-98889bf3abd4",
    "outputId": "4f7fdd6f-1255-4429-c17f-7a3c5f970052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 06:58:46.416098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-10 06:58:46.482067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-10 06:58:46.482759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of GPUs available\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07aa714f",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702553779333,
     "user": {
      "displayName": "Azimi2kht",
      "userId": "01921100736619125997"
     },
     "user_tz": -210
    },
    "id": "9edbe667"
   },
   "outputs": [],
   "source": [
    "# Setting the model parameters\n",
    "\n",
    "img_size = 352\n",
    "dataset_type = 'psfhs' # Options: kvasir/cvc-clinicdb/cvc-colondb/etis-laribpolypdb\n",
    "learning_rate = 1e-4\n",
    "seed_value = 58800\n",
    "filters = 17 # Number of filters, the paper presents the results with 17 and 34\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "ct = datetime.now()\n",
    "\n",
    "model_type = \"DuckNet\"\n",
    "\n",
    "progress_path = 'ProgressFull/' + dataset_type + '_progress_csv_' + model_type + '_filters_' + str(filters) +  '_' + str(ct) + '.csv'\n",
    "progressfull_path = 'ProgressFull/' + dataset_type + '_progress_' + model_type + '_filters_' + str(filters) + '_' + str(ct) + '.txt'\n",
    "plot_path = 'ProgressFull/' + dataset_type + '_progress_plot_' + model_type + '_filters_' + str(filters) + '_' + str(ct) + '.png'\n",
    "model_path = 'ModelSaveTensorFlow/' + dataset_type + '/' + model_type + '_filters_' + str(filters) + '_' + str(ct)\n",
    "\n",
    "EPOCHS = 600\n",
    "min_loss_for_saving = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a271814",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 502969,
     "status": "ok",
     "timestamp": 1702554282301,
     "user": {
      "displayName": "Azimi2kht",
      "userId": "01921100736619125997"
     },
     "user_tz": -210
    },
    "id": "264050d8",
    "outputId": "1b37bcdd-f2b7-454b-e972-7ee79e0e7d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks: 1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:02, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mImageLoader2D\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/psfh/src/models/Duck-Net/ImageLoader/ImageLoader2D.py:55\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(img_height, img_width, images_to_be_loaded, dataset)\u001b[0m\n\u001b[1;32m     52\u001b[0m     mask_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pillow_mask)\n\u001b[1;32m     54\u001b[0m     mask_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m127\u001b[39m\n\u001b[0;32m---> 55\u001b[0m     mask[:, :] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mmask_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m mask_threshold, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     57\u001b[0m     Y_train[n] \u001b[38;5;241m=\u001b[39m mask\n\u001b[1;32m     59\u001b[0m Y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(Y_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "X, Y = ImageLoader2D.load_data(img_size, img_size, -1, dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed4cc9",
   "metadata": {
    "executionInfo": {
     "elapsed": 3589,
     "status": "ok",
     "timestamp": 1702554285866,
     "user": {
      "displayName": "Azimi2kht",
      "userId": "01921100736619125997"
     },
     "user_tz": -210
    },
    "id": "75b6c029"
   },
   "outputs": [],
   "source": [
    "# Splitting the data, seed for reproducibility\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, shuffle= True, random_state = seed_value)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.111, shuffle= True, random_state = seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e4dfd",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1702554285867,
     "user": {
      "displayName": "Azimi2kht",
      "userId": "01921100736619125997"
     },
     "user_tz": -210
    },
    "id": "92a7b7d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pydantic serializer warnings:\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n"
     ]
    }
   ],
   "source": [
    "# Defining the augmentations\n",
    "\n",
    "aug_train = albu.Compose([\n",
    "    albu.HorizontalFlip(),\n",
    "    albu.VerticalFlip(),\n",
    "    albu.ColorJitter(brightness=(0.6,1.6), contrast=0.2, saturation=0.1, hue=0.01, always_apply=True),\n",
    "    albu.Affine(scale=(0.5,1.5), translate_percent=(-0.125,0.125), rotate=(-180,180), shear=(-22.5,22), always_apply=True),\n",
    "])\n",
    "\n",
    "def augment_images():\n",
    "    x_train_out = []\n",
    "    y_train_out = []\n",
    "\n",
    "    for i in range (len(x_train)):\n",
    "        ug = aug_train(image=x_train[i], mask=y_train[i])\n",
    "        x_train_out.append(ug['image'])\n",
    "        y_train_out.append(ug['mask'])\n",
    "\n",
    "    return np.array(x_train_out), np.array(y_train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc0279",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6886,
     "status": "ok",
     "timestamp": 1702554292749,
     "user": {
      "displayName": "Azimi2kht",
      "userId": "01921100736619125997"
     },
     "user_tz": -210
    },
    "id": "1609dd32",
    "outputId": "2a27a292-a3aa-483b-f382-da8afc060e5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 06:44:34.422323: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DUCK-Net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 06:44:34.423044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-10 06:44:34.424232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-10 06:44:34.427364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-10 06:44:35.513377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-10 06:44:35.514129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-10 06:44:35.514882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-10 06:44:35.515690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9972 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "\n",
    "model = DUCK_Net.create_model(img_height=img_size, img_width=img_size, input_chanels=3, out_classes=1, starting_filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c11e8",
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1702554292749,
     "user": {
      "displayName": "Azimi2kht",
      "userId": "01921100736619125997"
     },
     "user_tz": -210
    },
    "id": "2e513d42"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=dice_metric_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd031cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ef712b9",
    "outputId": "069e3897-d1e8-4bc9-98aa-6e8cbbd7794d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training, epoch 0\n",
      "Learning Rate: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning Rate: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(learning_rate))\n\u001b[1;32m     10\u001b[0m step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 12\u001b[0m image_augmented, mask_augmented \u001b[38;5;241m=\u001b[39m \u001b[43maugment_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m csv_logger \u001b[38;5;241m=\u001b[39m CSVLogger(progress_path, append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mimage_augmented, y\u001b[38;5;241m=\u001b[39mmask_augmented, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(x_valid, y_valid), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[csv_logger])\n",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36maugment_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m y_train_out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;28mlen\u001b[39m(x_train)):\n\u001b[0;32m---> 15\u001b[0m     ug \u001b[38;5;241m=\u001b[39m \u001b[43maug_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     x_train_out\u001b[38;5;241m.\u001b[39mappend(ug[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     17\u001b[0m     y_train_out\u001b[38;5;241m.\u001b[39mappend(ug[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/psfh/lib/python3.9/site-packages/albumentations/core/composition.py:256\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    253\u001b[0m     p\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transforms:\n\u001b[0;32m--> 256\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_each_transform:\n\u001b[1;32m    259\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_post_transform(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/psfh/lib/python3.9/site-packages/albumentations/core/transforms_interface.py:97\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeterministic:\n\u001b[1;32m     96\u001b[0m         kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_key][\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m deepcopy(params)\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/psfh/lib/python3.9/site-packages/albumentations/core/transforms_interface.py:108\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key2func \u001b[38;5;129;01mand\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     target_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key2func[key]\n\u001b[0;32m--> 108\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/psfh/lib/python3.9/site-packages/albumentations/augmentations/transforms.py:2333\u001b[0m, in \u001b[0;36mColorJitter.apply\u001b[0;34m(self, img, brightness, contrast, saturation, hue, order, **params)\u001b[0m\n\u001b[1;32m   2331\u001b[0m color_transforms \u001b[38;5;241m=\u001b[39m [brightness, contrast, saturation, hue]\n\u001b[1;32m   2332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m order:\n\u001b[0;32m-> 2333\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_transforms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m   2334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/psfh/lib/python3.9/site-packages/albumentations/augmentations/functional.py:1351\u001b[0m, in \u001b[0;36madjust_hue_torchvision\u001b[0;34m(img, factor)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _adjust_hue_torchvision_uint8(img, factor)\n\u001b[1;32m   1350\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2HSV)\n\u001b[0;32m-> 1351\u001b[0m img[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m360\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m360\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_HSV2RGB)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "step = 0\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "\n",
    "    print(f'Training, epoch {epoch}')\n",
    "    print('Learning Rate: ' + str(learning_rate))\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    image_augmented, mask_augmented = augment_images()\n",
    "\n",
    "    csv_logger = CSVLogger(progress_path, append=True, separator=';')\n",
    "\n",
    "    model.fit(x=image_augmented, y=mask_augmented, epochs=1, batch_size=4, validation_data=(x_valid, y_valid), verbose=1, callbacks=[csv_logger])\n",
    "\n",
    "    prediction_valid = model.predict(x_valid, verbose=0)\n",
    "    loss_valid = dice_metric_loss(y_valid, prediction_valid)\n",
    "\n",
    "    loss_valid = loss_valid.numpy()\n",
    "    print(\"Loss Validation: \" + str(loss_valid))\n",
    "\n",
    "    prediction_test = model.predict(x_test, verbose=0)\n",
    "    loss_test = dice_metric_loss(y_test, prediction_test)\n",
    "    loss_test = loss_test.numpy()\n",
    "    print(\"Loss Test: \" + str(loss_test))\n",
    "\n",
    "    with open(progressfull_path, 'a') as f:\n",
    "        f.write('epoch: ' + str(epoch) + '\\nval_loss: ' + str(loss_valid) + '\\ntest_loss: ' + str(loss_test) + '\\n\\n\\n')\n",
    "\n",
    "    if min_loss_for_saving > loss_valid:\n",
    "        min_loss_for_saving = loss_valid\n",
    "        print(\"Saved model with val_loss: \", loss_valid)\n",
    "        model.save(model_path)\n",
    "\n",
    "    del image_augmented\n",
    "    del mask_augmented\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d8c8b",
   "metadata": {
    "id": "2cd52447"
   },
   "outputs": [],
   "source": [
    "# Computing the metrics and saving the results\n",
    "\n",
    "print(\"Loading the model\")\n",
    "\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={'dice_metric_loss':dice_metric_loss})\n",
    "\n",
    "prediction_train = model.predict(x_train, batch_size=4)\n",
    "prediction_valid = model.predict(x_valid, batch_size=4)\n",
    "prediction_test = model.predict(x_test, batch_size=4)\n",
    "\n",
    "print(\"Predictions done\")\n",
    "\n",
    "dice_train = f1_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n",
    "                           np.ndarray.flatten(prediction_train > 0.5))\n",
    "dice_test = f1_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n",
    "                          np.ndarray.flatten(prediction_test > 0.5))\n",
    "dice_valid = f1_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n",
    "                           np.ndarray.flatten(prediction_valid > 0.5))\n",
    "\n",
    "print(\"Dice finished\")\n",
    "\n",
    "\n",
    "miou_train = jaccard_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n",
    "                           np.ndarray.flatten(prediction_train > 0.5))\n",
    "miou_test = jaccard_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n",
    "                          np.ndarray.flatten(prediction_test > 0.5))\n",
    "miou_valid = jaccard_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n",
    "                           np.ndarray.flatten(prediction_valid > 0.5))\n",
    "\n",
    "print(\"Miou finished\")\n",
    "\n",
    "\n",
    "precision_train = precision_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n",
    "                                  np.ndarray.flatten(prediction_train > 0.5))\n",
    "precision_test = precision_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n",
    "                                 np.ndarray.flatten(prediction_test > 0.5))\n",
    "precision_valid = precision_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n",
    "                                  np.ndarray.flatten(prediction_valid > 0.5))\n",
    "\n",
    "print(\"Precision finished\")\n",
    "\n",
    "\n",
    "recall_train = recall_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n",
    "                            np.ndarray.flatten(prediction_train > 0.5))\n",
    "recall_test = recall_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n",
    "                           np.ndarray.flatten(prediction_test > 0.5))\n",
    "recall_valid = recall_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n",
    "                            np.ndarray.flatten(prediction_valid > 0.5))\n",
    "\n",
    "print(\"Recall finished\")\n",
    "\n",
    "\n",
    "accuracy_train = accuracy_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n",
    "                                np.ndarray.flatten(prediction_train > 0.5))\n",
    "accuracy_test = accuracy_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n",
    "                               np.ndarray.flatten(prediction_test > 0.5))\n",
    "accuracy_valid = accuracy_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n",
    "                                np.ndarray.flatten(prediction_valid > 0.5))\n",
    "\n",
    "\n",
    "print(\"Accuracy finished\")\n",
    "\n",
    "\n",
    "final_file = 'results_' + model_type + '_' + str(filters) + '_' + dataset_type + '.txt'\n",
    "print(final_file)\n",
    "\n",
    "with open(final_file, 'a') as f:\n",
    "    f.write(dataset_type + '\\n\\n')\n",
    "    f.write('dice_train: ' + str(dice_train) + ' dice_valid: ' + str(dice_valid) + ' dice_test: ' + str(dice_test) + '\\n\\n')\n",
    "    f.write('miou_train: ' + str(miou_train) + ' miou_valid: ' + str(miou_valid) + ' miou_test: ' + str(miou_test) + '\\n\\n')\n",
    "    f.write('precision_train: ' + str(precision_train) + ' precision_valid: ' + str(precision_valid) + ' precision_test: ' + str(precision_test) + '\\n\\n')\n",
    "    f.write('recall_train: ' + str(recall_train) + ' recall_valid: ' + str(recall_valid) + ' recall_test: ' + str(recall_test) + '\\n\\n')\n",
    "    f.write('accuracy_train: ' + str(accuracy_train) + ' accuracy_valid: ' + str(accuracy_valid) + ' accuracy_test: ' + str(accuracy_test) + '\\n\\n\\n\\n')\n",
    "\n",
    "print('File done')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
